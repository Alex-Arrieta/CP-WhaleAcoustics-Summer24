{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ecba855-7642-4952-a089-878a1a3f1a29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#This notebook exists just to take an existing training manifest and remove rows such that the classes are 50/50 balanced\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import random\n",
    "\n",
    "training_list_path = \"train/train_lst.lst\"\n",
    "validation_list_path = \"validation/validation_lst.lst\"\n",
    "data_bucket_name = \"summer2024-sagemaker-data-bucket\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9972970-7cf9-48dc-8df8-260626676f43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       index  Classification  \\\n",
      "0          1               0   \n",
      "1          2               1   \n",
      "2          4               1   \n",
      "3          5               0   \n",
      "4          6               1   \n",
      "...      ...             ...   \n",
      "14438  17983               1   \n",
      "14439  17984               1   \n",
      "14440  17985               1   \n",
      "14441  17987               0   \n",
      "14442  17988               0   \n",
      "\n",
      "                                                    File  \n",
      "0           images/6805.230201090825_processed.wav_1.png  \n",
      "1           images/6805.230201090825_processed.wav_2.png  \n",
      "2           images/6805.230201090825_processed.wav_4.png  \n",
      "3           images/6805.230201090825_processed.wav_5.png  \n",
      "4           images/6805.230201090825_processed.wav_6.png  \n",
      "...                                                  ...  \n",
      "14438  images/671658014.181007153417_processed.wav_17...  \n",
      "14439  images/671658014.181007153417_processed.wav_17...  \n",
      "14440  images/671658014.181007153417_processed.wav_17...  \n",
      "14441  images/671658014.181007153417_processed.wav_17...  \n",
      "14442  images/671658014.181007153417_processed.wav_17...  \n",
      "\n",
      "[14443 rows x 3 columns]\n",
      "9341\n",
      "5102\n",
      "14443\n",
      "4239\n",
      "       index  Classification  \\\n",
      "0          1               0   \n",
      "1          2               1   \n",
      "2          4               1   \n",
      "4          6               1   \n",
      "5          7               0   \n",
      "...      ...             ...   \n",
      "14438  17983               1   \n",
      "14439  17984               1   \n",
      "14440  17985               1   \n",
      "14441  17987               0   \n",
      "14442  17988               0   \n",
      "\n",
      "                                                    File  \n",
      "0           images/6805.230201090825_processed.wav_1.png  \n",
      "1           images/6805.230201090825_processed.wav_2.png  \n",
      "2           images/6805.230201090825_processed.wav_4.png  \n",
      "4           images/6805.230201090825_processed.wav_6.png  \n",
      "5           images/6805.230201090825_processed.wav_7.png  \n",
      "...                                                  ...  \n",
      "14438  images/671658014.181007153417_processed.wav_17...  \n",
      "14439  images/671658014.181007153417_processed.wav_17...  \n",
      "14440  images/671658014.181007153417_processed.wav_17...  \n",
      "14441  images/671658014.181007153417_processed.wav_17...  \n",
      "14442  images/671658014.181007153417_processed.wav_17...  \n",
      "\n",
      "[10204 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "KEYS = \"ajarriet_accessKeys.csv\" # change to your path\n",
    "# KEYS = '/Users/sophiapchung/Desktop/Bioacoustics/spchung_accessKeys.csv'\n",
    "    \n",
    "keyInfo = pd.read_csv(KEYS)\n",
    "\n",
    "# Create a boto3 resource with your credentials\n",
    "s3 = boto3.resource(\n",
    "    's3',\n",
    "    region_name='us-west-2',\n",
    "    aws_access_key_id=keyInfo[\"Access key ID\"][0],\n",
    "    aws_secret_access_key=keyInfo[\"Secret access key\"][0]\n",
    ")\n",
    "data_bucket = s3.Bucket(data_bucket_name)\n",
    "\n",
    "#This downloads the original training manifest\n",
    "data_bucket.download_file(training_list_path, \"training_lst.lst\")\n",
    "\n",
    "trainDF = pd.read_csv(\"training_lst.lst\", sep = \"\\t\", names = [\"index\", \"Classification\", \"File\"])\n",
    "TotalYes = trainDF[\"Classification\"].sum()\n",
    "TotalNo = len(trainDF.index)-TotalYes\n",
    "\n",
    "print(trainDF)\n",
    "\n",
    "print(TotalNo)\n",
    "print(TotalYes)\n",
    "print(len(trainDF.index))\n",
    "print(TotalNo - TotalYes)\n",
    "\n",
    "#This samples random rows from the dataframe that have a \"no\" classification\n",
    "#It samples the difference in the amount of no and yes responses\n",
    "#The rows it samples are dropped from the manifest (note all the images files are still in the s3 bucket)\n",
    "#This does assume there are more images classified as \"no\" than \"yes\"\n",
    "toDrop = random.sample(trainDF[trainDF[\"Classification\"] == 0].index.tolist(), TotalNo - TotalYes)\n",
    "stratifiedDF = trainDF.drop(toDrop)\n",
    "#stratifiedDF[\"File\"] = stratifiedDF[\"File\"].apply(lambda x: x[6:])\n",
    "print(stratifiedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30c669ae-0245-4dc0-b0c2-3aaa73ebfe96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stratifiedDF.to_csv(\"stratified_train.csv\", sep = \"\\t\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb4d824f-e217-4aa2-b38a-e799006d4e41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_bucket.upload_file(\"stratified_train.csv\", \"train/train_lst.lst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7204f01f-3551-43c2-a48e-0aec360255f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10204"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stratifiedDF.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efa353f9-082c-40d4-80da-0a94f60b437c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stratifiedDF[\"Classification\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d95f590-e7c4-44aa-8555-2fd4eda818fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35325070968635325"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF[\"Classification\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d75c9fa-e328-4d10-8253-fd7f5fa7fd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      index  Classification                                              File\n",
      "0         6               1      images/6805.230201090825_processed.wav_6.png\n",
      "1         7               0      images/6805.230201090825_processed.wav_7.png\n",
      "2        10               0     images/6805.230201090825_processed.wav_10.png\n",
      "3        11               0     images/6805.230201090825_processed.wav_11.png\n",
      "4        13               0     images/6805.230201090825_processed.wav_13.png\n",
      "...     ...             ...                                               ...\n",
      "2215  10931               1  images/6805.230207120827_processed.wav_10931.png\n",
      "2216  10937               0  images/6805.230207120827_processed.wav_10937.png\n",
      "2217  10942               1  images/6805.230207120827_processed.wav_10942.png\n",
      "2218  10945               0  images/6805.230207120827_processed.wav_10945.png\n",
      "2219  10956               0  images/6805.230207120827_processed.wav_10956.png\n",
      "\n",
      "[2220 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "data_bucket.download_file(validation_list_path, \"validation_lst.lst\")\n",
    "\n",
    "trainDF = pd.read_csv(\"validation_lst.lst\", sep = \"\\t\", names = [\"index\", \"Classification\", \"File\"])\n",
    "trainDF[\"File\"] = trainDF[\"File\"].apply(lambda x: x[33:])\n",
    "\n",
    "print(trainDF)\n",
    "trainDF.to_csv(\"stratified_val.csv\", sep = \"\\t\", header = False, index = False)\n",
    "data_bucket.upload_file(\"stratified_val.csv\", \"LongTermPreprocessedImageStorage/validation/validation_lst.lst\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
